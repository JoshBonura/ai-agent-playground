allel=max_parallel, use_js=False, telemetry=tel["fetch1"]
    )
    tel["fetch1"]["roundSec"] = round(time.perf_counter() - t_f, 6)

    texts: List[Tuple[str, str, str]] = []
    quality_scores: List[float] = []
    for original_url, res in results:
        if not res:
            continue
        final_url, status, text = res
        title = next((t for (t, u) in meta if u == original_url), final_url)
        qscore = content_quality_score(text or "")
        quality_scores.append(qscore)
        if text:
            texts.append((title, final_url, text))
    tel["fetch1"]["docs"] = {"ok": len(texts), "qAvg": (sum(quality_scores)/len(quality_scores) if quality_scores else 0.0)}

    # optional JS retry
    try_js = False
    if enable_js_retry and quality_scores:
        avg_q = sum(quality_scores) / len(quality_scores)
        lowish = sum(1 for q in quality_scores if q < js_low_q_thresh)
        if avg_q < js_avg_q_thresh or (lowish / max(1, len(quality_scores))) >= js_lowish_ratio:
            try_js = True
        tel["jsRetry"] = {
            "considered": True, "triggered": try_js,
            "avgQ": round(avg_q, 4),
            "lowishRatio": round((lowish / max(1, len(quality_scores))) * 1.0, 4),
            "thresholds": {"avg": js_avg_q_thresh, "low": js_low_q_thresh, "ratio": js_lowish_ratio},
        }
    else:
        tel["jsRetry"] = {"considered": bool(enable_js_retry), "triggered": False}

    if try_js:
        js_timeout   = min(per_timeout + js_timeout_add, js_timeout_cap)
        js_parallel  = max(js_min_parallel, max_parallel + js_parallel_delta)
        tel["fetch2"] = {"timeoutSec": js_timeout, "maxParallel": js_parallel}
        results_js = await _fetch_round(
            urls, meta, per_url_timeout_s=js_timeout, max_parallel=js_parallel, use_js=True, telemetry=tel["fetch2"]
        )
        texts_js: List[Tuple[str, str, str]] = []
        for original_url, res in results_js:
            if not res:
                continue
            final_url, status, text = res
            title = next((t for (t, u) in meta if u == original_url), final_url)
            if text:
                texts_js.append((title, final_url, text))
        if texts_js:
            texts = texts_js

    if not texts:
        tel["elapsedSec"] = round(time.perf_counter() - start_time, 6)
        print("[web-block] (empty) â€” no fetched texts")
        return None, tel

    # sort by content quality (generic)
    texts.sort(key=lambda t: content_quality_score(t[2]), reverse=True)

    # ====== PER-HOST QUOTA ASSEMBLY ======
    # group fetched docs by host
    by_host: Dict[str, List[Tuple[str, str, str]]] = defaultdict(list)
    for title, url, text in texts:
        by_host[_host(url)].append((title, url, text))

    # keep each host's best doc first
    for h in by_host:
        by_host[h].sort(key=lambda x: content_quality_score(x[2]), reverse=True)

    # order hosts by the strength of their best doc
    hosts_ordered = sorted(by_host.keys(), key=lambda h: content_quality_score(by_host[h][0][2]), reverse=True)

    header = header_tpl.format(query=query)
    sep = sep_str
    available = max(min_block_reserve, total_char_budget - len(header) - len(sep))

    # compute a fair per-host quota so no site can hog the whole block
    min_hosts = max(1, min(_as_int("web_orch_min_hosts"), len(hosts_ordered))) if "web_orch_min_hosts" in globals() or "web_orch_min_hosts" in locals() else 3
    # equal-share starting point; clamp by per_doc_budget
    per_host_quota = max(min_chunk_after * 2, available // max(min_hosts, cfg_k))
    per_host_quota = min(per_host_quota, per_doc_budget)

    block_parts: List[str] = []
    used = 0
    included_hosts: List[str] = []

    # pass 1: guarantee at least one chunk per top hosts within their quota
    for h in hosts_ordered:
        title, url, text = by_host[h][0]
        chunk = condense_doc(title, url, text, max_chars=per_host_quota)
        sep_len = len(sep) if block_parts else 0
        if used + sep_len + len(chunk) > available:
            rem = available - used - sep_len
            if rem > min_chunk_after:
                chunk = _head_tail(chunk, rem)
            else:
                break
        block_parts.append(chunk)
        included_hosts.append(h)
        used += sep_len + len(chunk)
        if len(included_hosts) >= min_hosts and used >= int(available * 0.66):
            # decent diversity; move on to optional extras
            break

    # pass 2: fill remaining space with next-best docs across hosts (still capped by per_doc_budget)
    # build a round-robin of second-best, third-best, ...
    layer = 1
    while used < available:
        added_any = False
        for h in hosts_ordered:
            if layer >= len(by_host[h]):
                continue
            title, url, text = by_host[h][layer]
            sep_len = len(sep) if block_parts else 0
            chunk = condense_doc(title, url, text, max_chars=per_doc_budget)
            if used + sep_len + len(chunk) > available:
                rem = available - used - sep_len
                if rem <= min_chunk_after:
                    continue
                chunk = _head_tail(chunk, rem)
                if used + sep_len + len(chunk) > available:
                    continue
            block_parts.append(chunk)
            used += sep_len + len(chunk)
            added_any = True
            if used >= available:
                break
        if not added_any:
            break
        layer += 1
    # ====== /PER-HOST QUOTA ASSEMBLY ======

    body = sep.join(block_parts)
    block = f"{header}{sep}{body}" if body else header

    tel["assembly"] = {
        "chunksPicked": len(block_parts),
        "chars": len(block),
        "available": available,
        "headerChars": len(header),
        "hostsIncluded": len(included_hosts),
        "perHostQuota": per_host_quota,
    }
    tel["elapsedSec"] = round(time.perf_counter() - start_time, 6)

    # Always print what is being sent
    print("[web-block] -------- BEGIN --------")
    print(block)
    print("[web-block] --------  END  --------")
    try:
        srcs = [{"title": t, "url": u} for (t, u, _) in texts[:10]]
        print("[web-block] sources:", srcs)
    except Exception as _e:
        print("[web-block] sources: <unavailable>", str(_e))

    return block, tel

# ===== aimodel/file_read/web/orchestrator_common.py =====

# aimodel/file_read/web/orchestrator_common.py
from __future__ import annotations
from typing import List, Tuple, Optional, Dict, Any
from urllib.parse import urlparse
import re
from ..utils.text import clean_ws
from ..core.settings import SETTINGS
from .provider import SearchHit
from .fetch import fetch_many

def _req(key: str):
    return SETTINGS[key]

def _as_int(key: str) -> int: return int(_req(key))
def _as_float(key: str) -> float: return float(_req(key))
def _as_bool(key: str) -> bool: return bool(_req(key))
def _as_str(key: str) -> str:
    v = _req(key)
    return "" if v is None else str(v)

def _host(url: str) -> str:
    h = (urlparse(url).hostname or "").lower()
    pref = _as_str("web_orch_www_prefix")
    return h[len(pref):] if pref and h.startswith(pref) else h

def _tokens(s: str) -> List[str]:
    return re.findall(r"\w+", (s or "").lower())

def _head_tail(text: str, max_chars: int) -> str:
    t = text or ""
    if max_chars <= 0 or len(t) <= max_chars:
        return clean_ws(t)

    ellipsis = _as_str("web_orch_ellipsis")
    # 40% head, 20% middle, 40% tail (generic)
    reserve = len(ellipsis) * 2
    avail = max(0, max_chars - reserve)
    if avail <= 0:
        return clean_ws(t[:max_chars])

    head_len = max(1, int(avail * 0.4))
    mid_len  = max(1, int(avail * 0.2))
    tail_len = max(1, avail - head_len - mid_len)

    n = len(t)
    # head
    h0, h1 = 0, min(head_len, n)
    head = t[h0:h1]

    # middle (centered)
    m0 = max(0, (n // 2) - (mid_len // 2))
    m1 = min(n, m0 + mid_len)
    # ensure middle starts after head if they overlap heavily
    if m0 < h1 and (h1 + mid_len) <= n:
        m0, m1 = h1, min(n, h1 + mid_len)
    mid = t[m0:m1]

    # tail
    t0 = max(m1, n - tail_len)  # avoid overlapping mid/tail
    tail = t[t0:n] if tail_len > 0 else ""

    return clean_ws(head + ellipsis + mid + ellipsis + tail)

def condense_doc(title: str, url: str, text: str, *, max_chars: int) -> str:
    body = _head_tail(text or "", max_chars)
    safe_title = clean_ws(title or url)
    bullet = _as_str("web_orch_bullet_prefix") or "- "
    indent = _as_str("web_orch_indent_prefix") or "  "
    return f"{bullet}{safe_title}\n{indent}{url}\n{indent}{body}"

def score_hit(hit: SearchHit, query: str) -> int:
    w_exact = _as_int("web_orch_score_w_exact")
    w_substr = _as_int("web_orch_score_w_substr")
    w_title_full = _as_int("web_orch_score_w_title_full")
    w_title_part = _as_int("web_orch_score_w_title_part")
    w_snip_touch = _as_int("web_orch_score_w_snip_touch")
    score = 0
    q = (query or "").strip().lower()
    title = (hit.title or "").strip()
    snippet = (hit.snippet or "").strip()
    title_l = title.lower()
    snip_l = snippet.lower()
    if q:
        if title_l == q:
            score += w_exact
        elif q in title_l:
            score += w_substr
    qtoks = _tokens(q)
    if qtoks:
        cov_title = sum(1 for t in qtoks if t in title_l)
        if cov_title == len(qtoks):
            score += w_title_full
        elif cov_title > 0:
            score += w_title_part
        if any(t in snip_l for t in qtoks):
            score += w_snip_touch
    return score

def _type_ratio(text: str, sub: str) -> float:
    if not text:
        return 1.0
    cnt = text.lower().count(sub)
    return float(cnt) / max(1, len(text))

def content_quality_score(text: str) -> float:
    if not text:
        return 0.0
    t = text.strip()
    n = len(t)
    len_div = _as_float("web_orch_q_len_norm_divisor")
    w_len = _as_float("web_orch_q_len_weight")
    w_div = _as_float("web_orch_q_diversity_weight")
    length_score = min(1.0, n / len_div) if len_div > 0 else 0.0
    toks = _tokens(t)
    if not toks:
        return 0.1 * length_score
    uniq = len(set(toks))
    diversity = uniq / max(1.0, float(len(toks)))
    pen = 0.0
    for rule in _req("web_orch_q_penalties"):
        token = str(rule.get("token") or "")
        mult = float(rule.get("mult") or 0.0)
        cap = float(rule.get("cap") or 1.0)
        pen += min(cap, _type_ratio(t, token) * mult)
    raw = (w_len * length_score) + (w_div * diversity) - pen
    return max(0.0, min(1.0, raw))

def _dedupe_by_host(scored_hits: List[Tuple[int, SearchHit]], k: int) -> List[SearchHit]:
    picked: List[SearchHit] = []
    seen_hosts = set()
    for s, h in sorted(scored_hits, key=lambda x: x[0], reverse=True):
        u = (h.url or "").strip()
        if not u:
            continue
        host = _host(u)
        if host in seen_hosts:
            continue
        seen_hosts.add(host)
        picked.append(h)
        if len(picked) >= k:
            break
    return picked

async def _fetch_round(
    urls: List[str],
    meta: List[Tuple[str, str]],
    per_url_timeout_s: float,
    max_parallel: int,
    use_js: bool = False,
    telemetry: Optional[Dict[str, Any]] = None,
) -> List[Tuple[str, Optional[Tuple[str, int, str]]]]:
    fetch_fn = fetch_many
    if use_js:
        try:
            from . import fetch as _fetch_mod
            fetch_fn = getattr(_fetch_mod, "fetch_many_js", fetch_many)
        except Exception:
            fetch_fn = fetch_many
    cap_mult = _as_float("web_orch_fetch_cap_multiplier")
    per_doc_budget = _as_int("web_orch_per_doc_char_budget")
    fetch_max_chars = _as_int("web_fetch_max_chars")
    per_doc_cap = min(int(per_doc_budget * cap_mult), fetch_max_chars)

    results = await fetch_fn(
        urls,
        per_timeout_s=per_url_timeout_s,
        cap_chars=per_doc_cap,
        max_parallel=max_parallel,
        telemetry=telemetry,
    )
    return results

# ===== aimodel/file_read/web/provider.py =====

from __future__ import annotations
from dataclasses import dataclass
from typing import List, Optional

@dataclass
class SearchHit:
    title: str
    url: str
    snippet: Optional[str] = None
    rank: int = 0

class SearchProvider:
    async def search(self, query: str, k: int = 3) -> List[SearchHit]:
        raise NotImplementedError

# ===== aimodel/file_read/web/query_summarizer.py =====

# aimodel/file_read/web/query_summarizer.py
from __future__ import annotations
from typing import Any, Iterable, Dict, Tuple
import re, time
from ..core.settings import SETTINGS
from ..utils.streaming import safe_token_count_messages

def _tokens(s: str) -> set[str]:
    return set(re.findall(r"\w+", (s or "").lower()))

def _as_list(v) -> list:
    if v is None:
        return []
    if isinstance(v, (list, tuple)):
        return list(v)
    return [v]

def summarize_query(llm: Any, user_text: str) -> Tuple[str, Dict[str, Any]]:
    telemetry: Dict[str, Any] = {}
    txt = (user_text or "").strip()

    bypass_enabled = SETTINGS.get("query_sum_bypass_short_enabled")
    short_chars = SETTINGS.get("query_sum_short_max_chars")
    short_words = SETTINGS.get("query_sum_short_max_words")
    if bypass_enabled is True and isinstance(short_chars, int) and isinstance(short_words, int):
        if len(txt) <= short_chars and len(txt.split()) <= short_words:
            telemetry.update({"bypass": True})
            return txt, telemetry
    telemetry.update({"bypass": False})

    prompt = SETTINGS.get("query_sum_prompt")
    if isinstance(prompt, str) and "{text}" in prompt:
        params = {}
        max_tokens = SETTINGS.get("query_sum_max_tokens")
        if isinstance(max_tokens, int):
            params["max_tokens"] = max_tokens
        temperature = SETTINGS.get("query_sum_temperature")
        if isinstance(temperature, (int, float)):
            params["temperature"] = float(temperature)
        top_p = SETTINGS.get("query_sum_top_p")
        if isinstance(top_p, (int, float)):
            params["top_p"] = float(top_p)
        stops = _as_list(SETTINGS.get("query_sum_stop"))
        if stops:
            params["stop"] = [str(s) for s in stops if isinstance(s, str)]
        params["stream"] = False

        t_start = time.perf_counter()
        out = llm.create_chat_completion(
            messages=[{"role": "user", "content": prompt.format(text=txt)}],
            **params,
        )
        elapsed = time.perf_counter() - t_start
        result = (out["choices"][0]["message"]["content"] or "").strip()
        in_tokens = safe_token_count_messages(llm, [{"role": "user", "content": prompt.format(text=txt)}]) or 0
        out_tokens = safe_token_count_messages(llm, [{"role": "assistant", "content": result}]) or 0
        telemetry.update({
            "elapsedSec": round(elapsed, 4),
            "inputTokens": in_tokens,
            "outputTokens": out_tokens,
        })
    else:
        return txt, telemetry

    overlap_enabled = SETTINGS.get("query_sum_overlap_check_enabled")
    j_min = SETTINGS.get("query_sum_overlap_jaccard_min")
    if overlap_enabled is True and isinstance(j_min, (int, float)):
        src_toks = _tokens(txt)
        out_toks = _tokens(result)
        if not result or not out_toks:
            telemetry.update({"overlapRetained": True, "overlapScore": 0.0})
            return txt, telemetry
        jaccard = (len(src_toks & out_toks) / len(src_toks | out_toks)) if (src_toks or out_toks) else 1.0
        telemetry.update({"overlapScore": round(jaccard, 4)})
        if jaccard < float(j_min):
            telemetry.update({"overlapRetained": True})
            return txt, telemetry
        telemetry.update({"overlapRetained": False})
        return result, telemetry

    return result, telemetry

# ===== aimodel/file_read/web/router_ai.py =====

from __future__ import annotations
from typing import Tuple, Optional, Any, Dict
import json, re, time
from ..core.settings import SETTINGS
from ..utils.streaming import safe_token_count_messages
from ..utils.text import strip_wrappers as _strip_wrappers

def _force_json(s: str) -> dict:
    if not s:
        return {}
    raw = s.strip()
    try:
        cf = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", raw, re.IGNORECASE)
        if cf:
            raw = cf.group(1).strip()
    except Exception:
        pass
    try:
        v = json.loads(raw)
        return v if isinstance(v, dict) else {}
    except Exception:
        pass
    try:
        m = None
        for m in re.finditer(r"\{[^{}]*\"need\"\s*:\s*(?:true|false|\"true\"|\"false\")[^{}]*\}", raw, re.IGNORECASE):
            pass
        if m:
            frag = m.group(0)
            v = json.loads(frag)
            return v if isinstance(v, dict) else {}
    except Exception:
        pass
    try:
        last = None
        for last in re.finditer(r"\{[\s\S]*\}", raw):
            pass
        if last:
            frag = last.group(0)
            v = json.loads(frag)
            return v if isinstance(v, dict) else {}
    except Exception:
        pass
    return {}

def decide_web(llm: Any, user_text: str) -> Tuple[bool, Optional[str], Dict[str, Any]]:
    telemetry: Dict[str, Any] = {}
    try:
        if not user_text or not user_text.strip():
            return (False, None, telemetry)
        t_start = time.perf_counter()
        t_raw = user_text.strip()
        if SETTINGS.get("router_strip_wrappers_enabled") is True:
            core_text = _strip_wrappers(
                t_raw,
                trim_whitespace=SETTINGS.get("router_trim_whitespace") is True,
                split_on_blank=SETTINGS.get("router_strip_split_on_blank") is True,
                header_regex=SETTINGS.get("router_strip_header_regex"),
            )
        else:
            core_text = t_raw.strip() if SETTINGS.get("router_trim_whitespace") is True else t_raw
        prompt_tpl = SETTINGS.get("router_decide_prompt")
        if not isinstance(prompt_tpl, str) or not prompt_tpl.strip():
            return (False, None, telemetry)
        the_prompt = _safe_prompt_format(prompt_tpl, text=core_text)
        params = {
            "max_tokens": SETTINGS.get("router_decide_max_tokens"),
            "temperature": SETTINGS.get("router_decide_temperature"),
            "top_p": SETTINGS.get("router_decide_top_p"),
            "stream": False,
        }
        stop_list = SETTINGS.get("router_decide_stop")
        if isinstance(stop_list, list) and stop_list:
            params["stop"] = stop_list
        params = {k: v for k, v in params.items() if v is not None}
        raw_out_obj = llm.create_chat_completion(
            messages=[{"role": "user", "content": the_prompt}],
            **params,
        )
        text_out = (raw_out_obj.get("choices", [{}])[0]
                                  .get("message", {})
                                  .get("content") or "").strip()
        telemetry["rawRouterOut"] = text_out[:2000]
        data = _force_json(text_out) or {}
        need_val = data.get("need", None)
        if isinstance(need_val, str):
            nv = need_val.strip().lower()
            if nv in ("true", "yes", "y", "1"):
                need_val = True
            elif nv in ("false", "no", "n", "0"):
                need_val = False
        if isinstance(need_val, bool):
            need = need_val
            parsed_ok = True
        else:
            parsed_ok = False
            need_default = SETTINGS.get("router_default_need_when_invalid")
            need = bool(need_default) if isinstance(need_default, bool) else False
        query_field = data.get("query", "")
        try:
            if SETTINGS.get("router_strip_wrappers_enabled") is True:
                query = _strip_wrappers(
                    str(query_field or "").strip(),
                    trim_whitespace=SETTINGS.get("router_trim_whitespace") is True,
                    split_on_blank=SETTINGS.get("router_strip_split_on_blank") is True,
                    header_regex=SETTINGS.get("router_strip_header_regex"),
                )
            else:
                query = str(query_field or "").strip()
        except Exception:
            query = ""
        if not need:
            query = None
        t_elapsed = time.perf_counter() - t_start
        in_tokens = safe_token_count_messages(llm, [{"role": "user", "content": the_prompt}]) or 0
        out_tokens = safe_token_count_messages(llm, [{"role": "assistant", "content": text_out}]) or 0
        telemetry.update({
            "needed": bool(need),
            "routerQuery": query if need else None,
            "elapsedSec": round(t_elapsed, 4),
            "inputTokens": in_tokens,
            "outputTokens": out_tokens,
            "parsedOk": parsed_ok,
        })
        return (need, query, telemetry)
    except Exception:
        return (False, None, telemetry)

async def decide_web_and_fetch(llm: Any, user_text: str, *, k: int = 3) -> Tuple[Optional[str], Dict[str, Any]]:
    telemetry: Dict[str, Any] = {}
    need, proposed_q, tel_decide = decide_web(llm, (user_text or "").strip())
    telemetry.update(tel_decide)
    if not need:
        return None, telemetry
    from .query_summarizer import summarize_query
    from .orchestrator import build_web_block
    if SETTINGS.get("router_strip_wrappers_enabled") is True:
        base_query = _strip_wrappers(
            (proposed_q or user_text).strip(),
            trim_whitespace=SETTINGS.get("router_trim_whitespace") is True,
            split_on_blank=SETTINGS.get("router_strip_split_on_blank") is True,
            header_regex=SETTINGS.get("router_strip_header_regex"),
        )
    else:
        base_query = (proposed_q or user_text).strip()
    try:
        q_summary, tel_sum = summarize_query(llm, base_query)
        if SETTINGS.get("router_strip_wrappers_enabled") is True:
            q_summary = _strip_wrappers(
                (q_summary or "").strip(),
                trim_whitespace=SETTINGS.get("router_trim_whitespace") is True,
                split_on_blank=SETTINGS.get("router_strip_split_on_blank") is True,
                header_regex=SETTINGS.get("router_strip_header_regex"),
            ) or base_query
        else:
            q_summary = (q_summary or "").strip() or base_query
        telemetry["summarizer"] = tel_sum
        telemetry["summarizedQuery"] = q_summary
    except Exception:
        q_summary = base_query
    t_start = time.perf_counter()
    try:
        block_res = await build_web_block(q_summary, k=k)
        if isinstance(block_res, tuple):
            block, tel_orch = block_res
            telemetry["orchestrator"] = tel_orch or {}
        else:
            block = block_res
    except Exception:
        block = None
    t_elapsed = time.perf_counter() - t_start
    telemetry.update({
        "fetchElapsedSec": round(t_elapsed, 4),
        "blockChars": len(block) if block else 0,
    })
    return (block or None, telemetry)

def _safe_prompt_format(tpl: str, **kwargs) -> str:
    marker = "__ROUTER_TEXT_FIELD__"
    tmp = tpl.replace("{text}", marker)
    tmp = tmp.replace("{", "{{").replace("}", "}}")
    tmp = tmp.replace(marker, "{text}")
    return tmp.format(**kwargs)

# ===== aimodel/file_read/workers/retitle_worker.py =====

from __future__ import annotations
import asyncio, logging, re
from typing import Dict, List, Optional, Tuple
from ..runtime.model_runtime import get_llm
from ..store.index import load_index, save_index
from ..store.base import now_iso
from ..services.cancel import is_active, GEN_SEMAPHORE
from ..store.chats import _load_chat
from ..core.settings import SETTINGS

def S(key: str):
    return SETTINGS[key]

_PENDING: Dict[str, dict] = {}
_ENQUEUED: set[str] = set()
_queue: asyncio.Queue[str] = asyncio.Queue(maxsize=int(S("retitle_queue_maxsize")))
_lock = asyncio.Lock()

def _preview(s: str) -> str:
    n = int(S("retitle_preview_chars"))
    ell = S("retitle_preview_ellipsis")
    s = (s or "")
    return (s[:n] + ell) if len(s) > n else s

def _is_substantial(text: str) -> bool:
    t = (text or "").strip()
    min_chars = int(S("retitle_min_substantial_chars"))
    require_alpha = bool(S("retitle_require_alpha"))
    if len(t) < min_chars:
        return False
    return (re.search(r"[A-Za-z]", t) is not None) if require_alpha else True

def _pick_source(messages: List[dict]) -> Optional[str]:
    if not messages:
        return None
    min_user_len = int(S("retitle_min_user_chars"))
    for m in reversed(messages):
        if m.get("role") == "user":
            txt = (m.get("content") or "").strip()
            if len(txt) >= min_user_len and _is_substantial(txt):
                return txt
    for m in reversed(messages):
        if m.get("role") == "assistant":
            txt = (m.get("content") or "").strip()
            if _is_substantial(txt):
                return txt
    return None

def _sanitize_title(s: str) -> str:
    if not s:
        return ""
    s = s.strip()
    drop_prefix_re = S("retitle_sanitize_drop_prefix_regex")
    if drop_prefix_re:
        s = re.sub(drop_prefix_re, "", s)
    if bool(S("retitle_sanitize_strip_quotes")):
        s = s.strip().strip('"').strip("'").strip()
    replace_not_allowed_re = S("retitle_sanitize_replace_not_allowed_regex")
    replace_with = S("retitle_sanitize_replace_with")
    if replace_not_allowed_re:
        s = re.sub(replace_not_allowed_re, replace_with, s)
    s = re.sub(r"\s+", " ", s).strip()
    max_words = int(S("retitle_sanitize_max_words"))
    max_chars = int(S("retitle_sanitize_max_chars"))
    if max_words > 0:
        words = s.split()
        s = " ".join(words[:max_words])
    if max_chars > 0 and len(s) > max_chars:
        s = s[:max_chars].rstrip()
    return s

def _make_title(llm, src: str) -> str:
    hard = SETTINGS.get("retitle_llm_hard_prefix") or ""
    sys_extra = SETTINGS.get("retitle_llm_sys_inst") or ""
    sys = f"{hard}\n\n{sys_extra}".strip()
    user_text = f"{S('retitle_user_prefix')}{src}{S('retitle_user_suffix')}"
    messages = [
        {"role": "system", "content": sys},
        {"role": "user", "content": user_text},
    ]
    out = llm.create_chat_completion(
        messages=messages,
        max_tokens=int(S("retitle_llm_max_tokens")),
        temperature=float(S("retitle_llm_temperature")),
        top_p=float(S("retitle_llm_top_p")),
        stream=False,
        stop=S("retitle_llm_stop"),
    )
    raw = (out["choices"][0]["message"]["content"] or "").strip().strip('"').strip("'")
    strip_regex = SETTINGS.get("retitle_strip_regex")
    if strip_regex:
        raw = re.sub(strip_regex, "", raw).strip()
    raw = re.sub(r"^`{1,3}|`{1,3}$", "", raw).strip()
    raw = re.sub(r"[.:;,\-\s]+$", "", raw)
    return raw

async def start_worker():
    while True:
        sid = await _queue.get()
        try:
            await _process_session(sid)
        except Exception:
            logging.exception("Retitle worker failed")
        finally:
            _queue.task_done()

def _extract_job(snapshot: dict) -> Tuple[List[dict], int]:
    msgs = snapshot.get("messages") or []
    job_seq = int(snapshot.get("job_seq") or 0)
    return msgs, job_seq

async def _process_session(session_id: str):
    if not bool(S("retitle_enable")):
        return
    await asyncio.sleep(int(S("retitle_grace_ms")) / 1000.0)
    waited = 0
    backoff = int(S("retitle_active_backoff_start_ms"))
    backoff_max = int(S("retitle_active_backoff_max_ms"))
    backoff_total = int(S("retitle_active_backoff_total_ms"))
    growth = float(S("retitle_active_backoff_growth"))
    while is_active(session_id) and waited < backoff_total:
        await asyncio.sleep(backoff / 1000.0)
        waited += backoff
        backoff = min(int(backoff * growth), backoff_max)
    async with _lock:
        snapshot = _PENDING.pop(session_id, None)
        _ENQUEUED.discard(session_id)
    if not snapshot:
        return
    messages, job_seq = _extract_job(snapshot)
    try:
        cur_seq = int((_load_chat(session_id) or {}).get("seq") or 0)
    except Exception:
        cur_seq = job_seq
    if cur_seq > job_seq:
        return
    src = _pick_source(messages) or ""
    if not src.strip():
        return
    async with GEN_SEMAPHORE:
        llm = get_llm()
        try:
            title_raw = await asyncio.to_thread(_make_title, llm, src)
        except Exception as e:
            logging.exception("retitle: LLM error: %s", e)
            return
        finally:
            try:
                llm.reset()
            except Exception:
                pass
    title = _sanitize_title(title_raw) if bool(S("retitle_enable_sanitize")) else title_raw
    if not title:
        return
    idx = load_index()
    row = next((r for r in idx if r.get("sessionId") == session_id), None)
    if not row:
        return
    if (row.get("title") or "").strip() == title:
        return
    row["title"] = title
    row["updatedAt"] = now_iso()
    save_index(idx)

def enqueue(session_id: str, messages: List[dict], *, job_seq: Optional[int] = None):
    if not session_id:
        return
    if not isinstance(messages, list):
        messages = []
    if job_seq is None:
        try:
            job_seq = max(int(m.get("id") or 0) for m in messages) if messages else 0
        except Exception:
            job_seq = 0
    snap = {"messages": messages, "job_seq": int(job_seq)}
    async def _put():
        async with _lock:
            _PENDING[session_id] = snap
            if session_id not in _ENQUEUED:
                _ENQUEUED.add(session_id)
                try:
                    _queue.put_nowait(session_id)
                except Exception as e:
                    logging.warning(f"Failed to enqueue retitle: {e}")
    try:
        loop = asyncio.get_running_loop()
        loop.create_task(_put())
    except RuntimeError:
        asyncio.run(_put())

# ===== cloudflare/license-do.ts =====

// aimodel/file_read/cloudflare/license-do.ts
import type { DurableObjectState, DurableObjectStorage } from "@cloudflare/workers-types";

export class LicenseStore {
  state: DurableObjectState;
  storage: DurableObjectStorage;
  constructor(state: DurableObjectState) {
    this.state = state;
    this.storage = state.storage;
  }
  async fetch(req: Request) {
    const url = new URL(req.url);
    if (req.method === "POST" && url.pathname === "/put") {
      const { key, value } = await req.json<any>();
      if (!key || !value) return new Response(JSON.stringify({ error: "bad_request" }), { status: 400, headers: { "content-type": "application/json" } });
      await this.storage.put(key, value);
      return new Response(null, { status: 204 });
    }
    if (req.method === "GET" && url.pathname === "/get") {
      const key = url.searchParams.get("key") || "";
      const value = await this.storage.get<any>(key);
      return new Response(JSON.stringify(value ?? null), { status: 200, headers: { "content-type": "application/json" } });
    }
    return new Response("not found", { status: 404 });
  }
}

# ===== cloudflare/package.json =====

{
  "name": "lic-server",
  "private": true,
  "devDependencies": {
    "@cloudflare/workers-types": "^4.20250906.0",
    "wrangler": "^3.114.14"
  },
  "type": "module",
  "scripts": {
    "dev": "wrangler dev",
    "deploy": "wrangler deploy"
  },
  "dependencies": {
    "tweetnacl": "^1.0.3"
  }
}

# ===== cloudflare/tsconfig.json =====

{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "Bundler",
    "lib": ["ES2022", "WebWorker", "DOM", "DOM.Iterable"],
    "types": ["@cloudflare/workers-types"],
    "strict": true
  },
  "include": ["**/*.ts"]
}

# ===== cloudflare/worker-licensing.ts =====

// aimodel/file_read/cloudflare/worker-licensing.ts
import type { ExecutionContext, DurableObjectNamespace } from "@cloudflare/workers-types";
import nacl from "tweetnacl";
export { LicenseStore } from "./license-do";

export interface Env {
  APP_BASE_URL: string;
  PORTAL_RETURN_URL?: string;
  STRIPE_SECRET_KEY: string;
  STRIPE_WEBHOOK_SECRET: string;
  PRICE_MONTHLY_ID: string;
  LIC_ED25519_PRIV_HEX: string;
  LIC_ED25519_PUB_HEX: string;
  LICENSES: DurableObjectNamespace;
  ADMIN_KEY?: string;
}

function withCORS(res: Response, origin = "*") {
  const h = new Headers(res.headers);
  h.set("Access-Control-Allow-Origin", origin);
  h.set("Vary", "Origin");
  return new Response(res.body, { status: res.status, headers: h });
}
const allowOrigin = (req: Request) => req.headers.get("Origin") || "*";

function html(body: string, status = 200, headers: Record<string, string> = {}) {
  return new Response(body, { status, headers: { "content-type": "text/html; charset=utf-8", ...headers } });
}
function json(obj: unknown, status = 200) {
  return new Response(JSON.stringify(obj), { status, headers: { "content-type": "application/json" } });
}
async function hmac256Hex(secret: string, payload: string) {
  const key = await crypto.subtle.importKey("raw", new TextEncoder().encode(secret), { name: "HMAC", hash: "SHA-256" }, false, ["sign"]);
  const sig = await crypto.subtle.sign("HMAC", key, new TextEncoder().encode(payload));
  return [...new Uint8Array(sig)].map(b => b.toString(16).padStart(2, "0")).join("");
}
function b64u(data: Uint8Array): string {
  let s = btoa(String.fromCharCode(...data));
  return s.replace(/\+/g, "-").replace(/\//g, "_").replace(/=+$/g, "");
}
function strToB64u(s: string) { return b64u(new TextEncoder().encode(s)); }
const nowSec = () => Math.floor(Date.now() / 1000);

type StoredLic = { license: string; email?: string; exp?: number };
async function readFromDO(env: Env, key: string) {
  const stub = env.LICENSES.get(env.LICENSES.idFromName("store"));
  const r = await stub.fetch("https://store/get?key=" + encodeURIComponent(key));
  if (!r.ok) return null;
  return (await r.json<any>()) as StoredLic | null;
}

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    const url = new URL(request.url);
    if (request.method === "OPTIONS") {
      return new Response(null, {
        headers: {
          "Access-Control-Allow-Origin": "*",
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type,Stripe-Signature,Authorization"
        }
      });
    }
    if (url.pathname === "/health") return json({ ok: true });
    if (url.pathname === "/pricing") {
      return html(`<!doctype html>
<title>LocalMind Pro</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<style>body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif;max-width:760px;margin:40px auto;padding:0 16px} .card{border:1px solid #ddd;border-radius:12px;padding:20px;margin:12px 0} button{border:1px solid #000;border-radius:10px;padding:10px 16px;background:#000;color:#fff;cursor:pointer} .muted{color:#555}</style>
<h1>Choose your plan</h1>
<div class="card">
  <h2>Free</h2>
  <ul class="muted"><li>Local only</li><li>Basic features</li></ul>
</div>
<div class="card">
  <h2>Pro â€” $9.99 / month</h2>
  <ul><li>All features unlocked</li><li>License works offline after activation</li></ul>
  <form method="POST" action="/api/checkout/session">
    <button type="submit">Go Pro</button>
  </form>
</div>`);
    }
    if (url.pathname === "/success") {
      const sid = url.searchParams.get("session_id") || "";
      if (!sid) return html("<p>Missing session_id.</p>", 400);
      const stub = env.LICENSES.get(env.LICENSES.idFromName("store"));
      const r = await stub.fetch("https://store/get?key=" + encodeURIComponent("sid:" + sid));
      const data = await r.json<any>();
      const lic = data?.license || "";
      const masked = lic ? lic.slice(0, 16) + "â€¦ (copy below)" : "(not ready yet â€” webhook may still be processing; refresh in a few seconds)";
      const deep = lic ? `localmind://activate?license=${encodeURIComponent(lic)}` : "#";
      return html(`<!doctype html>
<title>Activation</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<style>body{font-family:system-ui;max-width:760px;margin:40px auto;padding:0 16px} input{width:100%;padding:10px;border:1px solid #ccc;border-radius:8px;font-family:monospace} a.btn,button{display:inline-block;margin-top:10px;border:1px solid #000;border-radius:10px;padding:10px 16px;background:#000;color:#fff;text-decoration:none}</style>
<h1>You're Pro ðŸŽ‰</h1>
<p>Session: <code>${sid}</code></p>
<p><b>License:</b> ${masked}</p>
${lic ? `
<input id="lic" readonly value="${lic}"/>
<button onclick="navigator.clipboard.writeText(document.getElementById('lic').value)">Copy License</button>
<a class="btn" href="${deep}">Activate in app</a>
` : `<p>Please wait a moment then <a href="/success?session_id=${encodeURIComponent(sid)}">refresh</a>.</p>`}
`);
    }
    if (url.pathname === "/.well-known/licensing-public-key") {
      return json({ alg: "Ed25519", public_key_hex: env.LIC_ED25519_PUB_HEX });
    }
    if (request.method === "POST" && url.pathname === "/api/checkout/session") {
      type CheckoutBody = { email?: string };
      let email = "";
      try {
        const body = (await request.json()) as Partial<CheckoutBody>;
        email = typeof body.email === "string" ? body.email : "";
      } catch { email = ""; }
      const price = env.PRICE_MONTHLY_ID;
      const res = await fetch("https://api.stripe.com/v1/checkout/sessions", {
        method: "POST",
        headers: { Authorization: `Bearer ${env.STRIPE_SECRET_KEY}`, "Content-Type": "application/x-www-form-urlencoded" },
        body: new URLSearchParams({
          mode: "subscription",
          "line_items[0][price]": price,
          "line_items[0][quantity]": "1",
          success_url: `${env.APP_BASE_URL}/success?session_id={CHECKOUT_SESSION_ID}`,
          cancel_url: `${env.APP_BASE_URL}/pricing`,
          "automatic_tax[enabled]": "true",
          customer_email: email || "",
          client_reference_id: email || "anonymous",
          allow_promotion_codes: "true"
        })
      });
      const body = await res.json<any>();
      if (!res.ok) return withCORS(json(body, 400), allowOrigin(request));
      const wantsJSON = (request.headers.get("accept") || "").includes("application/json");
      if (wantsJSON) return withCORS(json({ url: body.url }), allowOrigin(request));
      return withCORS(html(`<!doctype html><meta http-equiv="refresh" content="0;url=${body.url}">Redirectingâ€¦`), allowOrigin(request));
    }
    if (request.method === "POST" && url.pathname === "/api/stripe/webhook") {
      const sig = request.headers.get("stripe-signature") || "";
      const raw = await request.text();
      const parts = sig.split(",").reduce((acc, kv) => { const [k, v] = kv.split("="); acc[k] = v; return acc; }, {} as Record<string, string>);
      const signedPayload = `${parts["t"]}.${raw}`;
      const expected = await hmac256Hex(env.STRIPE_WEBHOOK_SECRET, signedPayload);
      const provided = parts["v1"];
      if (!provided || provided.toLowerCase() !== expected.toLowerCase()) return json({ error: "signature_verify_failed" }, 400);
      const event = JSON.parse(raw);
      const type = event.type as string;
      const obj = event.data.object as any;
      if (type === "checkout.session.completed" || type === "invoice.paid") {
        const sessionId = obj.id || obj.checkout_session || "";
        const customerId = obj.customer || "";
        let email = "";
        if (customerId) {
          const c = await fetch(`https://api.stripe.com/v1/customers/${encodeURIComponent(customerId)}`, { headers: { Authorization: `Bearer ${env.STRIPE_SECRET_KEY}` } }).then(r => r.json<any>());
          email = c?.email || "";
        }
        const issued_at = nowSec();
        const exp = issued_at + 365 * 24 * 3600;
        const licenseClaims = { ver: 1, license_id: `lic_${sessionId || customerId || issued_at}`, sub: email || customerId || "unknown", plan: "pro", entitlements: ["all"], issued_at, exp };
        const privHex = env.LIC_ED25519_PRIV_HEX.trim();
        const priv = new Uint8Array(privHex.match(/.{1,2}/g)!.map(h => parseInt(h, 16)));
        let keypair: { secretKey: Uint8Array; publicKey: Uint8Array };
        if (priv.length === 32) keypair = nacl.sign.keyPair.fromSeed(priv);
        else if (priv.length === 64) keypair = { secretKey: priv, publicKey: priv.slice(32) };
        else return json({ error: "bad_private_key_length" }, 500);
        const payloadStr = JSON.stringify(licenseClaims);
        const payloadB64 = strToB64u(payloadStr);
        const sigBytes = nacl.sign.detached(new TextEncoder().encode(payloadStr), keypair.secretKey);
        const sigB64 = b64u(sigBytes);
        const license = `LM1.${payloadB64}.${sigB64}`;
        const stub = env.LICENSES.get(env.LICENSES.idFromName("store"));
        await stub.fetch("https://store/put", { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ key: "sid:" + (sessionId || customerId), value: { license, email, exp } }) });
        if (customerId) {
          await stub.fetch("https://store/put", { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ key: "cust:" + customerId, value: { license, email, exp } }) });
        }
        if (email) {
          await stub.fetch("https://store/put", { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ key: "email:" + email.toLowerCase(), value: { license, email, exp } }) });
        }
      }
      return json({ received: true }, 200);
    }
    if (request.method === "GET" && url.pathname === "/api/license/by-session") {
      const sid = url.searchParams.get("session_id") || "";
      if (!sid) return withCORS(json({ error: "missing_session_id" }, 400), allowOrigin(request));
      const rec = await readFromDO(env, "sid:" + sid);
      if (!rec?.license) return withCORS(json({ license: null }, 404), allowOrigin(request));
      return withCORS(json(rec), allowOrigin(request));
    }
    if (request.method === "GET" && url.pathname === "/api/license/by-customer") {
      const email = (url.searchParams.get("email") || "").toLowerCase().trim();
      if (!email) return withCORS(json({ error: "missing_email" }, 400), allowOrigin(request));
      let rec = await readFromDO(env, "email:" + email);
      if (!rec?.license) {
        const sr = await fetch("https://api.stripe.com/v1/customers?limit=1&email=" + encodeURIComponent(email), { headers: { Authorization: `Bearer ${env.STRIPE_SECRET_KEY}` } });
        const list = await sr.json<any>();
        const cust = list?.data?.[0];
        if (cust?.id) {
          rec = await readFromDO(env, "cust:" + cust.id);
          if (rec?.license) {
            const stub = env.LICENSES.get(env.LICENSES.idFromName("store"));
            await stub.fetch("https://store/put", { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ key: "email:" + email, value: rec }) });
          }
        }
      }
      if (!rec?.license) return withCORS(json({ license: null }, 404), allowOrigin(request));
      return withCORS(json(rec), allowOrigin(request));
    }
    if (request.method === "POST" && url.pathname === "/api/portal/session") {
      let email = "";
      try {
        const body = await request.json<any>();
        email = (body?.email || "").toLowerCase().trim();
      } catch {}
      if (!email) return withCORS(json({ error: "missing_email" }, 400), allowOrigin(request));
      const listRes = await fetch("https://api.stripe.com/v1/customers?limit=1&email=" + encodeURIComponent(email), { headers: { Authorization: `Bearer ${env.STRIPE_SECRET_KEY}` } });
      const list = await listRes.json<any>();
      const customer = list?.data?.[0];
      if (!customer?.id) return withCORS(json({ error: "customer_not_found" }, 404), allowOrigin(request));
      const pr = await fetch("https://api.stripe.com/v1/billing_portal/sessions", {
        method: "POST",
        headers: { Authorization: `Bearer ${env.STRIPE_SECRET_KEY}`, "Content-Type": "application/x-www-form-urlencoded" },
        body: new URLSearchParams({ customer: customer.id, return_url: env.PORTAL_RETURN_URL || env.APP_BASE_URL })
      });
      const portal = await pr.json<any>();
      if (!pr.ok) return withCORS(json(portal, 400), allowOrigin(request));
      return withCORS(json({ url: portal.url }), allowOrigin(request));
    }
    if (request.method === "GET" && url.pathname === "/__admin/by-email") {
      const k = url.searchParams.get("k") || "";
      if (!env.ADMIN_KEY || k !== env.ADMIN_KEY) return withCORS(json({ error: "forbidden" }, 403), allowOrigin(request));
      const email = (url.searchParams.get("email") || "").toLowerCase().trim();
      if (!email) return withCORS(json({ error: "missing_email" }, 400), allowOrigin(request));
      const rec = await readFromDO(env, "email:" + email);
      return withCORS(json(rec || { license: null }), allowOrigin(request));
    }
    return json({ error: "not_found" }, 404);
  }
};
